{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train & Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries that will be used by both fastText & XGBoost\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>trade</td>\n",
       "      <td>asian exporters fear damage from u s japan rif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>grain</td>\n",
       "      <td>china daily says vermin eat pct grain stocks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ship</td>\n",
       "      <td>australian foreign ship ban ends but nsw ports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gold</td>\n",
       "      <td>western mining to open new gold mine in austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>acq</td>\n",
       "      <td>sumitomo bank aims at quick recovery from merg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content\n",
       "0  trade  asian exporters fear damage from u s japan rif...\n",
       "1  grain  china daily says vermin eat pct grain stocks a...\n",
       "2   ship  australian foreign ship ban ends but nsw ports...\n",
       "3   gold  western mining to open new gold mine in austra...\n",
       "4    acq  sumitomo bank aims at quick recovery from merg..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../Data/train/Reuters/r52-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('../Data/test/Reuters/r52-test-all-terms.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastText (lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9256230529595015\n",
      "--- 4.2410008907318115 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Importing Libs that are useul to fastText\n",
    "\n",
    "import os\n",
    "from FasttextClassifier.FasttextClassifier import FasttextClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "#Creating column with the label in fastText format\n",
    "\n",
    "test['label'] = '__label__'+test['label']\n",
    "train['label'] = '__label__'+train['label']\n",
    "\n",
    "\n",
    "#saving train file\n",
    "train.to_csv('trainFT.txt', sep='\\t', header=None, index=False)\n",
    "test.to_csv('testFT.txt', sep='\\t', header=None, index=False)\n",
    "\n",
    "\n",
    "#Start time measurement\n",
    "start_time = time.time()\n",
    "\n",
    "#Create model and Test\n",
    "\n",
    "ft_model = FasttextClassifier(train_data='trainFT.txt')\n",
    "fastText_test=ft_model.fasttext_test('testFT.txt')\n",
    "fastText_accuracy= fastText_test[1]\n",
    "print (fastText_accuracy)\n",
    "fastText_execution_time= (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" % fastText_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7710280373831776\n",
      "--- 0.5479910373687744 seconds ---\n",
      "0.8376168224299065\n",
      "--- 0.652385950088501 seconds ---\n",
      "0.8621495327102804\n",
      "--- 0.4676952362060547 seconds ---\n",
      "0.8820093457943925\n",
      "--- 0.5669848918914795 seconds ---\n",
      "0.889018691588785\n",
      "--- 0.6625957489013672 seconds ---\n",
      "0.8987538940809969\n",
      "--- 0.6346862316131592 seconds ---\n",
      "0.9014797507788161\n",
      "--- 0.7328293323516846 seconds ---\n",
      "0.9073208722741433\n",
      "--- 0.8395016193389893 seconds ---\n",
      "0.9131619937694704\n",
      "--- 1.060866117477417 seconds ---\n",
      "0.9158878504672897\n",
      "--- 1.1804468631744385 seconds ---\n",
      "0.919392523364486\n",
      "--- 1.2246370315551758 seconds ---\n",
      "0.9244548286604362\n",
      "--- 1.3702881336212158 seconds ---\n",
      "0.9283489096573209\n",
      "--- 1.4455649852752686 seconds ---\n",
      "0.9283489096573209\n",
      "--- 1.5571932792663574 seconds ---\n",
      "0.92601246105919\n",
      "--- 1.544337272644043 seconds ---\n",
      "0.9256230529595015\n",
      "--- 1.7472760677337646 seconds ---\n",
      "0.9310747663551402\n",
      "--- 1.8911521434783936 seconds ---\n",
      "0.9287383177570093\n",
      "--- 1.966303825378418 seconds ---\n",
      "0.9264018691588785\n",
      "--- 2.06567120552063 seconds ---\n",
      "0.9256230529595015\n",
      "--- 2.382457971572876 seconds ---\n",
      "0.9306853582554517\n",
      "--- 2.495789051055908 seconds ---\n",
      "0.9283489096573209\n",
      "--- 2.495396137237549 seconds ---\n",
      "0.9256230529595015\n",
      "--- 2.772624969482422 seconds ---\n",
      "0.9295171339563862\n",
      "--- 4.116457223892212 seconds ---\n",
      "0.9283489096573209\n",
      "--- 2.900825023651123 seconds ---\n",
      "0.9306853582554517\n",
      "--- 3.10007381439209 seconds ---\n",
      "0.9287383177570093\n",
      "--- 3.0303592681884766 seconds ---\n",
      "0.9302959501557633\n",
      "--- 3.505980968475342 seconds ---\n",
      "0.9291277258566978\n",
      "--- 5.486960172653198 seconds ---\n",
      "0.9310747663551402\n",
      "--- 4.7551209926605225 seconds ---\n",
      "0.9271806853582555\n",
      "--- 3.8147382736206055 seconds ---\n",
      "0.9287383177570093\n",
      "--- 4.033591985702515 seconds ---\n",
      "0.9287383177570093\n",
      "--- 4.2419891357421875 seconds ---\n",
      "0.926791277258567\n",
      "--- 4.450858116149902 seconds ---\n",
      "0.9306853582554517\n",
      "--- 4.538995981216431 seconds ---\n",
      "0.9306853582554517\n",
      "--- 4.970632314682007 seconds ---\n",
      "0.9299065420560748\n",
      "--- 4.561822175979614 seconds ---\n",
      "0.927570093457944\n",
      "--- 5.788235187530518 seconds ---\n",
      "0.9306853582554517\n",
      "--- 4.857594966888428 seconds ---\n",
      "0.9287383177570093\n",
      "--- 4.864802598953247 seconds ---\n",
      "0.927570093457944\n",
      "--- 5.188853979110718 seconds ---\n",
      "0.9256230529595015\n",
      "--- 5.150400876998901 seconds ---\n",
      "0.9287383177570093\n",
      "--- 5.407653093338013 seconds ---\n",
      "0.9271806853582555\n",
      "--- 5.657630920410156 seconds ---\n",
      "0.9279595015576324\n",
      "--- 6.104742050170898 seconds ---\n",
      "0.92601246105919\n",
      "--- 5.752878904342651 seconds ---\n",
      "0.926791277258567\n",
      "--- 6.161130666732788 seconds ---\n",
      "0.9283489096573209\n",
      "--- 6.0989158153533936 seconds ---\n",
      "0.9299065420560748\n",
      "--- 6.842644929885864 seconds ---\n",
      "0.9302959501557633\n",
      "--- 6.519967079162598 seconds ---\n",
      "0.9279595015576324\n",
      "--- 7.51241397857666 seconds ---\n",
      "0.9283489096573209\n",
      "--- 8.06190299987793 seconds ---\n",
      "0.926791277258567\n",
      "--- 6.787042140960693 seconds ---\n",
      "0.9271806853582555\n",
      "--- 7.026098012924194 seconds ---\n",
      "0.9295171339563862\n",
      "--- 7.084875822067261 seconds ---\n",
      "0.9271806853582555\n",
      "--- 7.21094822883606 seconds ---\n"
     ]
    }
   ],
   "source": [
    "execTime_FT = []\n",
    "accFT_lst = []\n",
    "for epoch in range(1, 100):\n",
    "    start_time = time.time()\n",
    "    ft_model = FasttextClassifier(train_data='trainFT.txt', epoch=epoch)\n",
    "    fastText_execution_time = (time.time() - start_time)\n",
    "    execTime_FT.append(fastText_execution_time)\n",
    "    fastText_test = ft_model.fasttext_test('testFT.txt')\n",
    "    fastText_accuracy = fastText_test[1]\n",
    "    accFT_lst.append(fastText_accuracy)\n",
    "    print (fastText_accuracy)\n",
    "    print(\"--- %s seconds ---\" % fastText_execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastText (lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_test=ft_model.fasttext_test('testFT.txt')\n",
    "execTime_FT03 = []\n",
    "accFT_lst03 = []\n",
    "for epoch in range(1, 100):\n",
    "    start_time = time.time()\n",
    "    ft_model = FasttextClassifier(train_data='trainFT.txt', epoch=epoch, lr=0.3)\n",
    "    fastText_execution_time03 = (time.time() - start_time)\n",
    "    execTime_FT03.append(fastText_execution_time03)\n",
    "    fastText_test = ft_model.fasttext_test('testFT.txt')\n",
    "    fastText_accuracy03 = fastText_test[1]\n",
    "    accFT_lst03.append(fastText_accuracy03)\n",
    "    print (fastText_accuracy03)\n",
    "    print(\"--- %s seconds ---\" % fastText_execution_time03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libs that are useul to XGBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "from glove.glovevectorizer import GloveVectorizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load word vectors\n",
    "\n",
    "vectorizer = GloveVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.content) # get wordvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start time measurement\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xg_reg=xgb.XGBRegressor(objective='reg:linear',colsample_bytree=0.3,  n_estimators=10)\n",
    "trainLabelLst = list(dict.fromkeys(train.label))\n",
    "def get_label(label_str_lst, label_lst):\n",
    "    return_lst = []\n",
    "    for s1 in label_str_lst:\n",
    "        for i, label in enumerate(label_lst):\n",
    "            if s1 == label:\n",
    "                return_lst.append(i)\n",
    "    return return_lst\n",
    "\n",
    "\n",
    "# get label index\n",
    "\n",
    "train['label_idx'] = get_label(train['label'],trainLabelLst)\n",
    "Ytrain = train.label_idx\n",
    "\n",
    "data_dmmatrix= xgb.DMatrix(data=Xtrain,label=Ytrain)\n",
    "param = {\n",
    "    'max_depth': 10,\n",
    "    'eta': 1.0,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 52} \n",
    "epochs = 1\n",
    "\n",
    "model = xgb.train(param, data_dmmatrix, epochs)\n",
    "Xtest = vectorizer.transform(test.content)\n",
    "test['label_idx'] = get_label(test['label'],trainLabelLst)\n",
    "Ytest = test.label_idx\n",
    "xgb_test = xgb.DMatrix(Xtest, label=Ytest)\n",
    "predictions = model.predict(xgb_test)\n",
    "XGBoost_accuracy=accuracy_score(Ytest, predictions)\n",
    "print(XGBoost_accuracy)\n",
    "XGBoost_time= model.predict(xgb_test)\n",
    "XGBoost_execution_time= (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" % XGBoost_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execTime_XG = []\n",
    "accXG_lst = []\n",
    "for epochs in range(1, 100):\n",
    "    start_time = time.time()\n",
    "    model = xgb.train(param, data_dmmatrix, epochs)\n",
    "    XGBoost_execution_time = (time.time() - start_time)\n",
    "    execTime_XG.append(XGBoost_execution_time)\n",
    "    predictions = model.predict(xgb_test)\n",
    "    XGBoost_accuracy = accuracy_score(Ytest, predictions)\n",
    "    accXG_lst.append(XGBoost_accuracy)\n",
    "    print(XGBoost_accuracy)\n",
    "    print(\"--- %s seconds ---\" % XGBoost_execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg=xgb.XGBRegressor(objective='reg:linear',colsample_bytree=0.3,  n_estimators=10)\n",
    "trainLabelLst = list(dict.fromkeys(train.label))\n",
    "def get_label(label_str_lst, label_lst):\n",
    "    return_lst = []\n",
    "    for s1 in label_str_lst:\n",
    "        for i, label in enumerate(label_lst):\n",
    "            if s1 == label:\n",
    "                return_lst.append(i)\n",
    "    return return_lst\n",
    "\n",
    "\n",
    "# get label index\n",
    "\n",
    "train['label_idx'] = get_label(train['label'],trainLabelLst)\n",
    "Ytrain = train.label_idx\n",
    "\n",
    "data_dmmatrix= xgb.DMatrix(data=Xtrain,label=Ytrain)\n",
    "param = {\n",
    "    'max_depth': 10,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 52} \n",
    "epochs = 1\n",
    "\n",
    "model = xgb.train(param, data_dmmatrix, epochs)\n",
    "Xtest = vectorizer.transform(test.content)\n",
    "test['label_idx'] = get_label(test['label'],trainLabelLst)\n",
    "Ytest = test.label_idx\n",
    "xgb_test = xgb.DMatrix(Xtest, label=Ytest)\n",
    "\n",
    "execTime_XG_lr03 = []\n",
    "accXG_lst_lr03 = []\n",
    "for epochs in range(1, 100):\n",
    "    start_time = time.time()\n",
    "    model = xgb.train(param, data_dmmatrix, epochs)\n",
    "    XGBoost_execution_time = (time.time() - start_time)\n",
    "    execTime_XG_lr03.append(XGBoost_execution_time)\n",
    "    predictions = model.predict(xgb_test)\n",
    "    XGBoost_accuracy = accuracy_score(Ytest, predictions)\n",
    "    accXG_lst_lr03.append(XGBoost_accuracy)\n",
    "    print(XGBoost_accuracy)\n",
    "    print(\"--- %s seconds ---\" % XGBoost_execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               random_state=42, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=None, verbose = 1)\n",
    "\n",
    "train = pd.read_csv('../Data/train/Reuters/r52-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('../Data/test/Reuters/r52-test-all-terms.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n",
    "\n",
    "vectorizer = GloveVectorizer()\n",
    "\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "Ytrain = train.label\n",
    "Xtest = vectorizer.fit_transform(test.content)\n",
    "Ytest = test.label\n",
    "# create the model, train it, print scores\n",
    "model = RandomForestClassifier(n_estimators=1)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Number of estimators â‰  Number of epochs\n",
    "execTime_RF = []\n",
    "accRF_lst = []\n",
    "for estimators in range(1, 100):\n",
    "    start_time = time.time()\n",
    "    model = RandomForestClassifier(n_estimators = estimators)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    Random_Forest_execution_time = (time.time() - start_time)\n",
    "    execTime_RF.append(Random_Forest_execution_time)\n",
    "    Random_Forest_accuracy=model.score(Xtest, Ytest)\n",
    "    accRF_lst.append(Random_Forest_accuracy)\n",
    "    print(Random_Forest_accuracy)\n",
    "    print(\"--- %s seconds ---\" % Random_Forest_execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xg=plt.plot(execTime_XG, accXG_lst, label='XGBoost(lr=1)')\n",
    "xg_lr03=plt.plot(execTime_XG_lr03, accXG_lst_lr03, label='XGBoost(lr=0.3)')\n",
    "ftext=plt.plot(execTime_FT, accFT_lst, label= \"FastText(lr=1)\")\n",
    "ftext03=plt.plot(execTime_FT03, accFT_lst03, label= \"FastText (lr=0.3)\")\n",
    "rf=plt.plot(execTime_RF,accRF_lst, label='Random Forest')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.title(\"Accuracy vs. Training Time\")\n",
    "#plt.savefig('accuracy_training.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize_set=8\n",
    "xg=plt.scatter(execTime_XG, accXG_lst, label='XGBoost(lr=1)', s = markersize_set)\n",
    "xg_lr03=plt.scatter(execTime_XG_lr03, accXG_lst_lr03, label='XGBoost(lr=0.3)', s = markersize_set)\n",
    "ftext=plt.scatter(execTime_FT, accFT_lst, label= \"FastText(lr=1)\", s = markersize_set)\n",
    "ftext03=plt.scatter(execTime_FT03, accFT_lst03, label= \"FastText (lr=0.3)\", s = markersize_set)\n",
    "rf=plt.scatter(execTime_RF,accRF_lst, label='Random Forest', s = markersize_set)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.title(\"Accuracy vs. Training Time\")\n",
    "#plt.savefig('acctrain.eps', format='eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = execTime_XG\n",
    "y = accXG_lst\n",
    "\n",
    "x1 = execTime_XG_lr03\n",
    "y1 = accXG_lst_lr03\n",
    "\n",
    "x2 = execTime_FT\n",
    "y2 = accFT_lst\n",
    "\n",
    "x3 = execTime_FT03\n",
    "y3 = accFT_lst03\n",
    "\n",
    "x4 = execTime_RF\n",
    "y4 = accRF_lst\n",
    "\n",
    "# calculate polynomial\n",
    "z = np.polyfit(x, y, 3)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "z1 = np.polyfit(x1, y1, 3)\n",
    "f1 = np.poly1d(z1)\n",
    "\n",
    "z2 = np.polyfit(x2, y2, 3)\n",
    "f2 = np.poly1d(z2)\n",
    "\n",
    "z3 = np.polyfit(x3, y3, 3)\n",
    "f3 = np.poly1d(z3)\n",
    "\n",
    "z4 = np.polyfit(x4, y4, 3)\n",
    "f4 = np.poly1d(z4)\n",
    "\n",
    "# calculate new x's and y's\n",
    "x_new = np.linspace(x[0], x[-1], 500)\n",
    "y_new = f(x_new)\n",
    "\n",
    "x1_new = np.linspace(x1[0], x1[-1], 500)\n",
    "y1_new = f1(x1_new)\n",
    "\n",
    "x2_new = np.linspace(x2[0], x2[-1], 500)\n",
    "y2_new = f2(x2_new)\n",
    "\n",
    "x3_new = np.linspace(x3[0], x3[-1], 500)\n",
    "y3_new = f3(x3_new)\n",
    "\n",
    "x4_new = np.linspace(x4[0], x4[-1], 500)\n",
    "y4_new = f4(x4_new)\n",
    "\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.title(\"Accuracy vs. Training Time\")\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(x,y ,'o', x_new, y_new, markersize=3 , label='XGBoost(lr=1)')\n",
    "plt.plot(x1,y1 ,'o', x1_new, y1_new, markersize=3, label='XGBoost(lr=0.3)')\n",
    "plt.plot(x2,y2 ,'o', x2_new, y2_new, markersize=3, label=\"FastText(lr=1)\")\n",
    "plt.plot(x3,y3 ,'o', x3_new, y3_new, markersize=3, label=\"FastText(lr=0.3)\")\n",
    "plt.plot(x4,y4 ,'o', x4_new, y4_new, markersize=3, label=\"Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
