{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification by K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from glove.glovevectorizer import GloveVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------#\n",
    "train = pd.read_csv('../Data/train/Reuters/r8-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('../Data/test/Reuters/r8-test-all-terms.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n",
    "train['lenght'] = train['content'].str.len()\n",
    "lenght_mn=train['lenght'].mean()\n",
    "train['lenght_mean']=(lambda x: train['lenght']/lenght_mn)(train['lenght'].values)\n",
    "train['words_num'] = train['content'].str.split().str.len()\n",
    "train['words_len_med'] = train['content'].str.len()/train['words_num']\n",
    "train['words_num_norm'] = (train['words_num'] - train['words_num'].min())/(train['words_num'].max()-train['words_num'].min())\n",
    "train['words_len_med_norm'] = (train['words_len_med'] - train['words_len_med'].min())/(train['words_len_med'].max()-train['words_len_med'].min())\n",
    "train['lenght_norm'] = (train['lenght'] - train['lenght'].min())/(train['lenght'].max()-train['lenght'].min())\n",
    "train['words_num_norm'] = (train['words_num'] - train['words_num'].min())/(train['words_num'].max()-train['words_num'].min())\n",
    "train['words_len_med_norm'] = (train['words_len_med'] - train['words_len_med'].min())/(train['words_len_med'].max()-train['words_len_med'].min())\n",
    "\n",
    "#-------------------------------------------------------------------------------#\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = GloveVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "model_1=KMeans(n_clusters=8, init='random').fit(Xtrain)\n",
    "centroids = model_1.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Graph- 2 Features (Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zipped_data = np.array(list(zip(train.words_len_med_norm, train.lenght_norm)))\n",
    "model_2=KMeans(n_clusters=8, init='random').fit(zipped_data)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(zipped_data[:,0], zipped_data[:,1], c=model_2.labels_.astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Graph- 2 Features (Non Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_data = np.array(list(zip(train.words_len_med, train.lenght)))\n",
    "model_3=KMeans(n_clusters=8, init='random').fit(zipped_data)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(zipped_data[:,0], zipped_data[:,1], c=model_3.labels_.astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Dataset's Novel Features with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zipped_data = np.array(list(zip(train.lenght_norm,train.words_num_norm, train.words_len_med_norm)))\n",
    "\n",
    "model_4_fit=KMeans(n_clusters=8, init='random').fit(zipped_data)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(zipped_data[:,0],zipped_data[:,1], zipped_data[:,2], c=model_4_fit.labels_.astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(zipped_data[:,0],zipped_data[:,1], zipped_data[:,2], c=model_4_fit.labels_.astype(float))\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('lenght_norm')\n",
    "ax.set_ylabel('words_num_norm')\n",
    "ax.set_zlabel('words_len_med_norm')\n",
    "ax.set_title('K-Means Normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elbow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "list_k = list(range(1, 10))\n",
    "zipped_data = np.array(list(zip(train.lenght_norm,train.words_num_norm, train.words_len_med_norm)))\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(zipped_data)\n",
    "    sse.append(km.inertia_)\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "list_k = list(range(1, 10))\n",
    "vectorizer = GloveVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(Xtrain)\n",
    "    sse.append(km.inertia_)\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
