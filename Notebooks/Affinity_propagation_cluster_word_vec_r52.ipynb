{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "\n",
    "from glove.glovevectorizer import GloveVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/franc/OneDrive/Documentos/Projects/r52/tclass/Data/train/reuters_train_52/r52-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('C:/Users/franc/OneDrive/Documentos/Projects/r52/tclass/Data/test/reuters_test_52/r52-test-all-terms.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n",
    "train['lenght'] = train['content'].str.len()\n",
    "lenght_mn=train['lenght'].mean()\n",
    "train['lenght_mean']=(lambda x: train['lenght']/lenght_mn)(train['lenght'].values)\n",
    "train['words_num'] = train['content'].str.split().str.len()\n",
    "train['words_len_med'] = train['content'].str.len()/train['words_num']\n",
    "train['words_num_norm'] = (train['words_num'] - train['words_num'].min())/(train['words_num'].max()-train['words_num'].min())\n",
    "train['words_len_med_norm'] = (train['words_len_med'] - train['words_len_med'].min())/(train['words_len_med'].max()-train['words_len_med'].min())\n",
    "train['lenght_norm'] = (train['lenght'] - train['lenght'].min())/(train['lenght'].max()-train['lenght'].min())\n",
    "train['words_num_norm'] = (train['words_num'] - train['words_num'].min())/(train['words_num'].max()-train['words_num'].min())\n",
    "train['words_len_med_norm'] = (train['words_len_med'] - train['words_len_med'].min())/(train['words_len_med'].max()-train['words_len_med'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            content  lenght  \\\n",
      "0  cocoa  bahia cocoa review showers continued throughou...    2519   \n",
      "1   earn  champion products ch approves stock split cham...     361   \n",
      "2    acq  computer terminal systems cpml completes sale ...    1246   \n",
      "3   earn  cobanco inc cbco year net shr cts vs dlrs net ...     221   \n",
      "4   earn  am international inc am nd qtr jan oper shr lo...     465   \n",
      "\n",
      "   lenght_mean  words_num  words_len_med  words_num_norm  words_len_med_norm  \\\n",
      "0     3.881040        456       5.524123        0.436170            0.381910   \n",
      "1     0.556195         62       5.822581        0.055126            0.438223   \n",
      "2     1.919721        210       5.933333        0.198259            0.459119   \n",
      "3     0.340496         44       5.022727        0.037718            0.287307   \n",
      "4     0.716429         93       5.000000        0.085106            0.283019   \n",
      "\n",
      "   lenght_norm  \n",
      "0     0.408971  \n",
      "1     0.054387  \n",
      "2     0.199803  \n",
      "3     0.031384  \n",
      "4     0.071476  \n",
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Numer of samples with no words found: 0 / 6532\n"
     ]
    }
   ],
   "source": [
    "#Vectorizer variable\n",
    "print(train.head())\n",
    "vectorizer = GloveVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:152: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Fitting X using affinity Propagation Clustering\n",
    "zipped_data = np.array(list(zip(train.words_len_med_norm, train.lenght_norm)))\n",
    "afprop = AffinityPropagation(max_iter=1000)\n",
    "afprop.fit(zipped_data )\n",
    "labels = afprop.labels_\n",
    "cluster_centers_indices = afprop.cluster_centers_indices_\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "# Predict the cluster for all the samples\n",
    "P = afprop.predict(zipped_data)\n",
    "\n",
    "# Generate scatter plot for training data\n",
    "#print(\"Silhouette Coefficient: %0.3f\"\n",
    " #     % metrics.silhouette_score(Xtrain, labels, metric='sqeuclidean'))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.close('all')\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    class_members = labels == k\n",
    "    cluster_center = Xtrain[cluster_centers_indices[k]]\n",
    "    plt.plot(zipped_data[class_members, 0], zipped_data[class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in zipped_data[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
