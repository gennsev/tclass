{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train & Test\n",
    "train = pd.read_csv('r8-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('r8-test-all-terms.txt', header=None, sep='\\t')\n",
    "#Name the features\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg=xgb.XGBRegressor(objective='reg:linear',colsample_bytree=0.3, learning_rate=0.1,max_depth=5, alpha=10, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "  def __init__(self):\n",
    "    # load in pre-trained word vectors\n",
    "    print('Loading word vectors...')\n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    idx2word = []\n",
    "    with open('glove.6B.50d.txt',encoding='utf-8', errors='ignore') as f:\n",
    "      # is just a space-separated text file in the format:\n",
    "      # word vec[0] vec[1] vec[2] ...\n",
    "      for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "    # save for later\n",
    "    self.word2vec = word2vec\n",
    "    self.embedding = np.array(embedding)\n",
    "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "    self.V, self.D = self.embedding.shape\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.lower().split()\n",
    "      vecs = []\n",
    "      for word in tokens:\n",
    "        if word in self.word2vec:\n",
    "          vec = self.word2vec[word]\n",
    "          vecs.append(vec)\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earn', 'acq', 'trade', 'ship', 'grain', 'crude', 'interest', 'money-fx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabelLst = list(dict.fromkeys(train.label))\n",
    "trainLabelLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label_str_lst, label_lst):\n",
    "    return_lst = []\n",
    "    for s1 in label_str_lst:\n",
    "        for i, label in enumerate(label_lst):\n",
    "            if s1 in label:\n",
    "                return_lst.append(i)\n",
    "    return return_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Numer of samples with no words found: 0 / 5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "train['label_idx'] = get_label(train['label'],trainLabelLst)\n",
    "Ytrain = train.label_idx\n",
    "data_dmmatrix= xgb.DMatrix(data=Xtrain,label=Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 8} \n",
    "epochs = 10 \n",
    "\n",
    "model = xgb.train(param, data_dmmatrix, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 2189\n",
      "   label                                            content  label_idx\n",
      "0  trade  asian exporters fear damage from u s japan rif...          2\n",
      "1  grain  china daily says vermin eat pct grain stocks a...          4\n",
      "2   ship  australian foreign ship ban ends but nsw ports...          3\n",
      "3    acq  sumitomo bank aims at quick recovery from merg...          1\n",
      "4   earn  amatil proposes two for five bonus share issue...          0\n",
      "[2. 4. 3. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "Xtest = vectorizer.transform(test.content)\n",
    "test['label_idx'] = get_label(test['label'],trainLabelLst)\n",
    "print(test.head())\n",
    "Ytest = test.label_idx\n",
    "\n",
    "xgb_test = xgb.DMatrix(Xtest, label=Ytest)\n",
    "predictions = model.predict(xgb_test)\n",
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9195979899497487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Ytest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
